name: "no_dreamer"

environment:
  name: "Humanoid-v5"              # Name of the Gymnasium environment
  wrapper: None       # Wrapper for the environment (e.g., DreamWrapper or None)
  n_future_steps: 0        # Number of future steps for the wrapper (if using DreamWrapper)
  n_steps: 1024                # Number of steps in each environment rollout (for training)

ppo_hyperparameters:
  policy: 'MlpPolicy'
  batch_size: 64
  n_steps: 2048
  device: 'cpu'
  gamma: 0.95
  learning_rate: 2.5e-4
  ent_coef: 0
  clip_range: 0.2
  n_epochs: 10
  gae_lambda: 0.95
  # max_grad_norm: 2
  vf_coef: 0.431892
  verbose: 1
  policy_kwargs:
    log_std_init: -2
    ortho_init: False
    activation_fn: "ReLU"

    net_arch:
      pi: [256, 256]
      vf: [256, 256]

training:
  total_timesteps: 10000000    # Total number of timesteps to train the model
  save_wrapper_state_path: "dreamer_state_dict.pth" # Path to save the dreamer model state
